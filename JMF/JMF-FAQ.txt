=======
JMF FAQ
=======

General
-------
- How media is processed?

Configuration
-------------
- Where configuration of 'JMF Registry Editor' is stored?
- Howto create registry file?

Development
-----------
- How to get information about available plugins?
- Howto trace log of JMF?
- Preparing custom processing
- Howto add a renderer to a processor?
- Processing in details
- Lookup algorythm of processing elements
- What output content types are supported?
- How DataSources are created?
- How demultiplexers are selected for input data source?
- How chain built-up with custom processing?
- How media duration will be calculated?
- Call stack of media format chooser (Called from JMStudio)
- Format chooser in JMF
- How to add custom format (and payload type) to RTP session?


Samples
-------
- JMF Studio source in Maven project
- How to configure RTP session in JMStudio?

Troubleshooting
---------------
- Error during committing PluginManager (java.lang.reflect.InvocationTargetException)
- Exception: "Cannot find a DataSink for: ..."
- Exception: CannotRealizeException: Unable to provide all requested tracks
- Exception: Processor doesn't support requested output ContentDescriptor
- Exception: NoProcessorException: Cannot find a Processor for: ...
- Exception: CannotRealizeException (no message)
- Exception: NoProcessorException: Processor doesn't support output
- Log message: The input format is not compatible with the given codec plugin
- Log message:  No multiplexer is found for that content type
- Exception: Format of Stream not supported in RTP Session Manager

----------------------------------------------------------------------------------------------------------------------------
How media is processed?
=======================
Presentation:
	1. If the stream is multiplexed, the individual tracks are extracted.
	2. If the individual tracks are compressed, they are decoded.
	3. If necessary, the tracks are converted to a different format.
	4. Effect filters are applied to the decoded tracks (if desired).

Capturing:
	1. The audio and video tracks would be captured.
	2. Effect filters would be applied to the raw tracks (if desired).
	3. The individual tracks would be encoded.
	4. The compressed tracks would be multiplexed into a single media stream.
	5. The multiplexed media stream would then be saved to a file.

Processing steps:
	- Demultiplexing is the process of parsing the input stream. If the stream contains multiple tracks, 
		they are extracted and output separately.
		
	- Pre-Processing is the process of applying effect algorithms to the tracks extracted from the input stream.
	
	- Transcoding is the process of converting each track of media data fromone input format to another. 
		When a data stream is converted from a compressed type to an uncompressed type, it is generally referred to
		as decoding. Conversely, converting from an uncompressed type to a compressed type is referred to as encoding.
		
	- Post-Processing is the process of applying effect algorithms to decoded tracks.		
	
	- Multiplexing is the process of interleaving the transcoded media tracks into a single output stream. 
		For example, separate audio and video tracks might be multiplexed into a single MPEG-1 data stream.
		You can specify the data type of the output stream with the Processor setOutputContentDescriptor method.
		
	- Rendering is the process of presenting the media to the user.
	
Participants of processing:	

	- Demultiplexers and Multiplexers
		complex (multiplexed) media -> tracks
		tracks -> complex (multiplexed) media
		
	- Codecs
		compressed -> raw
		raw -> compressed
		
	- Effect Filters
		Effects applied on RAW data.
		
	- Renderers
		RAW data will be presented.
	
---------------------------------------------------------------------------------------------------------------------------
How to get information about available plugins?
===============================================
Call 'JMF Registry Editor'. You can get it in:
	- JMFRegistry application
	OR
	- JMStudio:	File/Preferences
	
	Features:
	- configure caching, logging
	- configure capture devices
	- get list of plugins (demultiplexers, codecs, effects, renderers, multiplexers)
	- get list of supported input/output formats of plugins
	- configure mime types

---------------------------------------------------------------------------------------------------------------------------
Howto trace JMF?
================
- In 'JMF Registry Editor' go to 'User Settings' tab.
- Set logging (will be saved into 'allowLogging' JMF registry entry).
- Set log target directory (saved into secure.logDir JMF registry entry)

Log is generated by:

	com.sun.media.Log
	
---------------------------------------------------------------------------------------------------------------------------
Where configuration of 'JMF Registry Editor' is stored?	
=======================================================
Configuration 


Configuration is managed by:

	com.sun.media.util.Registry
	
Registry values are persisted in

	jmf.properties

file in serialized format (see: com.sun.media.util.Registry.commit()).
File will be stored in classpath directories.

Hint:
	Generally you will find it in directory where jmf.jar resides.

Algorythm of registry file lookup in com.sun.media.util.Registry.findJMFPropertiesFile():
	- it gets the classpath
	- splits by path separator
	- if a token is a directory adds "jmf.properties"
	- if a token is a ZIP or a JAR it replaces file part with "jmf.properties"
	- it checks existance of file 
	
	
See more: 
	SOURCE:	com.sun.media.util.Registry.findJMFPropertiesFile()
	SOURCE:	javax.media.pm.PackageManager

---------------------------------------------------------------------------------------------------------------------------
Howto create registry file?
===========================
Use:
	com.sun.media.util.RegistryGen

 * A simple utility to create RegistryLib .
 *
 * To run:
 *	% javac RegistryGen.java
 *	% java RegistryGen [-d <destdir>] <registrylib>
 * The output is a file called registrylib.java at directory <destdir>
 * In case that registrylib contains a package it will be the registrylib's package
	

---------------------------------------------------------------------------------------------------------------------------
Error during committing PluginManager (java.lang.reflect.InvocationTargetException)	
===================================================================================
JMF persists settings into "jmf.properties".  PluginManager.commit() also tries to save data into 
this file. It calls Registry.commit() which throws an IOException if registry file not found.

Unfortunately this exception will be hidden by InvocationTargetException :(.

Solution:
	Place a jmf.properties file into classpath (may be next to JARs).
	If you put an empty one you will get an error (IOException in readRegistry: java.io.EOFException) but commit will fix it.
	

---------------------------------------------------------------------------------------------------------------------------
How to configure RTP session in JMStudio?
=========================================
- Start 2 JMStudio instances in 2 (or more) DIFFERENT machines.

- Method 1 - unicast:


- Method 2 - broadcast:
	- Server settings:
		- File/Transmit
		- Choose source media
		- Setup encoding	
		- Specify broadcast address of current network for multicast distribution (e.g. 192.168.5.255)
		- Specify port
			
	- Client setting:
		- File/Open RTP session
		- Specify ANY address in network (or the same broadcast address) and port

---------------------------------------------------------------------------------------------------------------------------
Preparing custom processing
===========================
You can control what processing is performed by a Processor several different ways:
	- Use a ProcessorModel to construct a Processor that has certain input and output characteristics.
	- Use the TrackControl setFormat method to specify what format conversions are performed on individual tracks.
	- Use the Processor setOutputContentDescriptor method to specify the multiplexed data format of the Processor objectOs output.
	- Use the TrackControl setCodecChain method to select the Effect or Codec plug-ins that are used by the Processor.
	- Use the TrackControl setRenderer method to select the Renderer plugin used by the Processor.

IMPORTANT NOTE:	
	If you add custom codecs JMF may add codecs to the start and to the end of chain to fit chain ends 
	to the input and output format.

For example:
	- custom processing uses GSM encoder
	- desired output format is uLAw 

	## Here's the completed flow graph:
		  com.sun.media.parser.audio.WavParser@687bc899					
			 connects to: com.ibm.media.codec.audio.PCMToPCM@16aeea66
			 format: LINEAR, 8000.0 Hz, 8-bit, Mono, Unsigned, 8000.0 frame rate, FrameSize=8 bits
		  com.ibm.media.codec.audio.PCMToPCM@16aeea66
			 connects to: com.ibm.media.codec.audio.gsm.JavaEncoder@53cffeb4													<--- because GSM Encoder expects 16-bit sample bits, but input has 8 bit
			 format: LINEAR, 8000.0 Hz, 16-bit, Mono, LittleEndian, Signed, 8000.0 frame rate, FrameSize=16 bits
		  com.ibm.media.codec.audio.gsm.JavaEncoder@53cffeb4														<--- this is custom codec
			 connects to: com.ibm.media.codec.audio.gsm.JavaDecoder@359eda2c
			 format: gsm, 8000.0 Hz, 16-bit, Mono, FrameSize=264 bits
		  com.ibm.media.codec.audio.gsm.JavaDecoder@359eda2c
			 connects to: com.ibm.media.codec.audio.ulaw.JavaEncoder@50059a34
			 format: LINEAR, 8000.0 Hz, 16-bit, Mono, LittleEndian, Signed
		  com.ibm.media.codec.audio.ulaw.JavaEncoder@50059a34								<--- for providing output format
			 connects to: com.sun.media.renderer.audio.JavaSoundRenderer@1629ce8c
			 format: ULAW, 8000.0 Hz, 8-bit, Mono, Unsigned, FrameSize=8 bits
 	
	
javax.media.Model.createRealizedProcessor(ProcessorModel model)
	
	Model specifies 
		- input (data source or locator) and  
		- output content type and 
		- desired output format(s). 
		
	Steps are:
	- Processor is created by input data source or locator
	
	- -------------> Processor getting into Configured state.
	
	- Checking if content type is in supported content types of processor 
		"Processor doesn't support requested  output ContentDescriptor" if not found
		
		That means there is no multiplexer which provides this content type on output.
		
	- First it compares desired output format(s) to default track formats 
	
	- Then it compares desired output format(s) to supported formats of tracks
		If a supported format matches track format will be set to this format.
		
	- If any (enabled) track doesn't have a default of supported format for output format(s) of processing you will get this message:
		"Unable to provide all requested tracks"
		
	- If all (enabled) tracks have a format for output formats the processor will be realized.

	- -------------> Processor getting into Realized state.

---------------------------------------------------------------------------------------------------------------------------
Howto add a renderer to a processor?
====================================
If you specify a content type of a processor data will be sent to dataOutput.
You have to set content type to 'null' if you want to redirect data to a renderer.

Selecting a Renderer:
	To select the Renderer that you want to use, you:
		1. Call getTrackControls on the Processor to get a TrackControl for each track in the media stream. 
			The Processor must in the Configured state before you call getTrackControls.
		2. Call the TrackControl setRenderer() method to specify the Renderer plug-in.
		
---------------------------------------------------------------------------------------------------------------------------
Processing in details
=====================
Manager.createDataSource(MediaLocator sourceLocator)
																					LOG:
																					## DataSource created: com.sun.media.protocol.file.DataSource@78cade31

Manager.createProcessor(DataSource source)
	-> Manager.createProcessorForSource(DataSource source, String contentTypeName, boolean sourceUsed[])

																					LOG:
																					## Processor created: com.sun.media.processor.unknown.Handler@4f62198b
																					##   using DataSource: com.sun.media.protocol.file.DataSource@78cade31 
																					
At the start of processing datasource and demultiplexer and processor will be created.

- DataSource are selected by PROTOCOL OF INPUT LOCATOR. 
	
	<protocol-prefix>.media.protocol.<protocol>.DataSource
	
	SEE MORE:	 Lookup algorythm of processing elements
	
- Demultiplexers are plugins that are loaded by PluginManager by CONTENT TYPE OF INPUT DATA SOURCE.

	SEE MORE:	Lookup algorythm of processing elements

- Processors:....	
		<prefix>.media.processor.<protocol>.Handler	

	SEE MORE:	How demultiplexers are selected for input data source?

After preparing processor realize() will be called. 

BasicController.process()
	-> ProcessEngine.doConfigure()
		
		Setting default of output content type to RAW.

Player.realize()
	-> BasicController.realize()
		... starting thread ...
		
		RealizeWorkThread.process()
			-> ProcessEngine.doRealize()
				-> PlaybackEngine.doRealize1()
																							LOG:
																							## Building flow graph for: file:/c:/Users/ftoth/Documents/media/x.g729
				
				----------------------- Loop on open tracks -----------------------------
					-> ProcessEngine$ProcTControl.buildTrack()													<<<<<<<<<<<<<<<<<<<<<<<< building track
						-> ProcessEngine$ProcGraphBuilder.buildGraph(BasicTrackControl tc, int trackID, int numTracks)
					
																							LOG:
																							## Building Track: 0
																							## Input: g729, 8000.0 Hz, 8-bit, Mono, Signed, 100.0 frame rate, FrameSize=8 bits
					
						if TrackControl customized :
						
							JMF will built a codec chain using your custom codecs to bind DEMUX to MUX.
							The final plugin chain looks like this:

								DataSource - DEMUX - [codecs BEFORE custom chain] - 1st codec - [codecs between N and N+1 node] - 2nd codec - [..... - last codec] - [codecs AFTER custom chain] - MUX - ....
							
						
							-> ProcessEngine$ProcGraphBuilder.buildCustomGraph(ProcTControl tc)					<<<<<<<<<<<<<<<<<< building custom graph for a track using forced custom codecs
								Here tc (track control) initialized:
									- tc.formatWanted 		: format wanted at the end of processing has been set during preparing codec chain for tracks  <------ track.setFormat(...)
									- tc.CodecChainWanted 	: custom codec chain fragment specified by user application during preparing codec chain for tracks
									- tc.track.format		: format of track media itself (so track related input format from datasource) returned by getOriginalFormat()
								
								
								if NOT a video format:
								-> ProcGraphBuilder.buildCustomGraph(Format in)	where 'in' contains track format (of input media)
								
																							LOG:
																							## Custom options specified.
								
									Here are checking codecs from chain one by one and will be joined to each other. 
									Output of previous codec to the possible input of next codec.
										
									- ProcGraphBuilder.codecs  : codec chain fragment array specified by user application
									
									----------------------- loop on custom codecs in chain fragment ----------------------------
																							LOG:
																							## A custom codec is specified: org.ftoth.general.util.jmf.g729.Packetizer@27f8922																							
																							
																												
										-> setTargetPlugin(codecs[i], PlugInManager.CODEC);							<<<<<<<<<<<<<<<<<<<< current codec in custom codec chain
									
											
											
												
											

										-> SimpleGraphBuilder.buildGraph(candidates)								<<<<<<<<<<<<<<<<<<<< building graph to join track (multiplexer)	and starting codec of custom codec chain together
											
											It build a graph until it reaches a target (so the starting codec of custom codec chain)
										
											----------------------- loop to consume candidates ----------------------------
											-> ProcGraphBuilder.doBuildGraph(candidates)
												- candidates	: contains the previous node, so contains format of track to be processed
												- node			: 1st candidate (removed from candidates) = 
										
											-> ProcGraphBuilder.buildGraph(candidates)									
												
						
												-> ProcGraphBuilder.findTarget(node)								<<<<<<<<<<<<<<<<<<<<< checking end of graph 
													- node		: node to decide if it's the end of chain (
												
													This detect when the search ends.  The "targets" array defines
													the nodes that are to be the "end points" (leaf nodes) of the graph.
													With the default graph builder, the targets array contains the
													list of sinks that can potentially support the input format.

																																			---> RETURN on end of building
																																			
													-> SimpleGraphBuilder.verifyTargetPlugins(GraphNode node, Format outs[]) 
														- node	: current node with input source or format
														- outs	: possible output formats
														
														To check if plugin (in node) is able to receive data from output of previous source
														
														------------------------ loop on target plugins --------------------------
														-> SimpleGraphBuilder.matches(Format outs[], Format ins[], PlugIn up, PlugIn down)		<<<<<<<<<<<<< Check for a match in the list of predefined targets.
														
																Choose a format among the two input arrays that matches and verify
																that if the given upstream and downstream plugins accept the matched
																format as output (for the upstream) or as input (for the downstream).													
														
																-------------------------- loop on formats ------------------------------
																--> SimpleGraphBuilder.verifyInput(down, fmt)
																	--> (Codec)p.setInputFormat(in);
																--> SimpleGraphBuilder.verifyOutput(up, fmt)
																	--> (Codec)p).setOutputFormat(out);
																	
																It joins current plugin upstream (up) to the downstream of next plugin in chain.
																During this process it tries to set input format of 'down' plugin and output 
																format of 'up' plugin. If both of format setting successfully plugins 
																can join to each other.
										
													
										>>>>>>>>>>>>>>>>>>>> If a plugin found during in buildGraph() it will be added to candidates.
										
									On end of codec loop processing output will be checked (outputContentDes != null).
									
																										LOG:
																										## An output format is specified: g729/rtp, 8000.0 Hz, 8-bit, Mono, FrameSize=8 bits 
																										
											--> ProcessEngine.setDefaultTargetMux()																<<<<<<<<<<<<<<<<<<<<<<< creating MUX
												Here MUX will be assigned to end of processing by output content type of processor.

																										LOG:
																										## An output content type is specified: raw.rtp
												
												Available multiplexers are loaded from PlugInManager by output format:
												
													--> PlugInManager.getPlugInList(null, outputContentDes, PlugInManager.MULTIPLEXER);											
														where:
														
															outputContentDes is content type has been specified for processor. 
												
												You can force a multiplexer by setting output content type of processor:
													
													processor.setContentDescriptor(contentType);
														--> MediaProcessor.setContentDescriptor(contentType);
															--> ProcessEngine.setContentDescriptor(contentType);
																
												BUT, you can specify only a supported content type otherwise default content type (RAW) will be used.
													Supported content type is which can be multiplexed.
													SEE MORE: How plugins are chosen during processing?
									
											--> buildGraph(candidates)																				<<<<<<<<<<<<<< binding codec chain to MUX
													targetPlugins	: null, chain should not be joined to a plugin but a format
													targetFormat	: format of processing (created MUX previously based on it)

													
						- if not customized chain:
							-> super.buildGraph() 			== SimpleGraphBuilder.buildGraph()
								
								-> setDefaultTargets(tc.getOriginalFormat()))	: to get default target
									if processor output content type is null 
										-> setDefaultTargetRenderer(in)	: to get default render for track format
											-> setDefaultTargetRenderer.setDefaultTargetRenderer(Format in)
											
									if processor output content type is NOT null 	
										-> setDefaultTargetMux()			: to get default multiplexer
						
---------------------------------------------------------------------------------------------------------------------------
How chain built-up with custom processing?							
==========================================
- DEMUX provides input of codec chain. If custom codec start cannot be joined directly to the output of DEMUX, codecs will be 
	inserted between them.

- If you specify custom codecs they won't always provide a continous chain fragment. If one codec cannot be joined to next 
	codec in chain, JMF tries to build a chain between them.

- Last codec will be plugged in to input of MUX. If custom codec end cannot be joined directly to the input of MUX, codecs will be 
	inserted between them.

So the final plugin chain looks like this:

	DataSource - DEMUX - [codecs BEFORE custom chain] - 1st codec - [codecs between N and N+1 node] - 2nd codec - [..... - last codec] - [codecs AFTER custom chain] - MUX - ....
	
	
---------------------------------------------------------------------------------------------------------------------------
Lookup algorythm of processing elements
=======================================
Classes are looked for this algorythm:

	<prefix>.<plugin-specific-part>.<content-specific-part>.DataSource	

	where:
		- prefix can be
			- protocol-prefix:	Manager.getProtocolPrefixList() (-> javax.media.pm.PackageManager.getProtocolPrefixList)
				
				[javax, com.sun, com.ibm]
		or 
			- content-prefix:	Manager.getContentPrefixList() (-> javax.media.pm.PackageManager.getContentPrefixList)
			
				[javax, com.sun, com.ibm]
			
			
		- plugin-specific-parts are different:
			- DataSource:		media.protocol
			- DataSink:			media.datasink
			- Processor:		media.processor
			
		- content-specific-part can be
			- protocol	(e.g: file)
			- content type (e.g: audio.x_wav)
			

DataSource:		DataSources are selected by PROTOCOL OF INPUT LOCATOR.

				<protocol-prefix>.media.protocol.<protocol>.DataSource

	SEE MORE:	How DataSources are created?
	
Demultiplexer:	Demultiplexers are plugins that are loaded by PluginManager by CONTENT TYPE OF INPUT DATA SOURCE.
		
	SEE MORE:	How demultiplexers are selected for input data source?
	
Multiplexer:	MUXs have been selected by OUTPUT FORMAT OF PROCESSOR.
	
	ProcessEngine.setDefaultTargetMux()	
	
	MUX won't be created when output format of processor is 'null'. In this case a renderer will be assigned.
	
	SEE MORE:	Processing in details
	
DataSink:	DataSinks are selected by protocol of output locator. 
			The FIRTS DataSink class will be selected that meets with protocol.
			
			<content-prefix>.media.datasink.<protocol>.Handler
			
	SEE MORE:	How to create a DataSink?
				What output content types are supported?
			
Codec:		input format of down-stream codec (next codec in chain) should match to 
			output format of up-stream codec.
			
Processor:	selected by content type of source

		<content-prefix>.media.processor.<content type>.Handler

	NOTE: if processor handler nor found with contentName, "unknown" will be applied as contentName and
	
			com.sun.media.processor.unknown.Handler
		
		will be used.
				
---------------------------------------------------------------------------------------------------------------------------
How DataSources are created?
============================
At the start of processing datasource and demultiplexer will be created:  
	
	Manager.createProcessorForContent(...)

DataSources are selected by PROTOCOL OF INPUT LOCATOR in the following way:

- It gets protocol from input locator.

- It creates handler candidate class list:
	
	<protocol-prefix>.media.protocol.<protocol>.DataSource
	
	e.g.:	media.protocol.file.DataSource, javax.media.protocol.file.DataSource, ...
	
- It tries to instantiate object.

- Sets locator of new DataSource object and connecting to it.

---------------------------------------------------------------------------------------------------------------------------
How demultiplexers are selected for input data source?
======================================================
Demultiplexers are plugins that are loaded by PluginManager by CONTENT TYPE OF INPUT DATA SOURCE.
During creating a processor Demultiplexer also will be created for input data source.

A possible call stack to create demultiplexer:

	Manager.createProcessor(MediaLocator sourceLocator)
		-> createProcessorForContent(...)
			Here DataSource is created by source locator.
			
			-> createProcessorForSource(source, source.getContentType(), sourceUsed);
				Here processor handler will queried by protocol of input locator. Name of candidate classes generated this way:
				
					"media.processor." + ContentDescriptor.mimeTypeToPackageName(contentName) + ".Handler";
					
				E.g. input content type "audio.g729" then candidate classes are:
					
					media.processor.audio.g729.Handler
					javax.media.processor.audio.g729.Handler
					com.sun.media.processor.audio.g729.Handler
					com.ibm.media.processor.audio.g729.Handler
					
				Algorythm is similar to getting DataSink handlers (SEE MORE: How to create a DataSink?)

				Result handler can:		unknown
				
			-> MediaProcessor.setSource(source);
				Handler gets DataSource here.
				
				-> PlaybackEngine.setSource(source);
				
					-> BasicSourceModule.createModule(ds);
					
						-> BasicSourceModule.createDemultiplexer(ds)
						
							Here DEMULTIPLEXER plugins are queried by supported input format,
							where input format is content type of input data source.
						
	NOTE: if processor handler nor found with contentName, "unknown" will be applied as contentName and
	
			com.sun.media.processor.unknown.Handler
		
		will be used.
---------------------------------------------------------------------------------------------------------------------------
How to create a DataSink?
=========================
DataSinks are selected by PROTOCOL OF OUTPUT LOCATOR.

To create a sink call:
	
		DataSink sink = Manager.createDataSink(inputSource, outputLocator);
		sink.addDataSinkListener(listener);
		sink.open();
	
Steps of sink creation:
	- creates handler name:		
	
		<content-prefix>.media.datasink.<protocol>.Handler
	
		For examle for file output:
		
			media.datasink.file.Handler
	
	- Manager gets content prefix list from javax.media.pm.PackageManager, e.g.: javax, com.sun, com.ibm
		and builds class list of candidate sinks, e.g:
		
			media.datasink.file.Handler, javax.media.datasink.file.Handler, com.sun.media.datasink.file.Handler, com.ibm.media.datasink.file.Handler
	
	- It enumerates class list and it tries to instantiate class. If class found and it implements DataSink:
		- it sets source of sink
			During setting source input datasource may be validated by type, e.g. com.sun.media.datasink.file.Handler accepts only PushDataSource or PullDataSource.
			
		- it sets output locator of sink
			
		
	- Algorythm ends on the FIRST usable DataSink object.
	
Other usable notes:	
- You can save data into file only from data sources which implements PushDataSource or PullDataSource


---------------------------------------------------------------------------------------------------------------------------
Exception: "Cannot find a DataSink for: ..."
============================================
Some DataSinks accepts only specific type of data sources, e.g file Handler can save data from PushDataSource or PullDataSource,
but not from RawBufferMux$RawBufferDataSource.

In this case multiplexer output provides bad type of data source. Multiplexers are selected by OUTPUT FORMAT OF PROCESSOR 
that is RAW by default if you specify a not supported output content type. 

In this case RAW content type will provide RawBufferMux and it will provide RawBufferDataSource whic


---------------------------------------------------------------------------------------------------------------------------
What output content types are supported?
========================================
Supported output content type is which can be multiplexed. To get supported output content types JMF enumerates all 
multiplexers and gets union of supported output formats.

Here:

	PorcessEngine.getSupportedContentDescriptors()


---------------------------------------------------------------------------------------------------------------------------
Exception: Processor doesn't support requested output ContentDescriptor
=======================================================================
You call Manager.createRealizedProcessor(ProcessorModel) but output content descriptor in model contains a not supported content type.

Supported output content type is which can be multiplexed. 

SEE MORE:	What output content types are supported?


---------------------------------------------------------------------------------------------------------------------------
Exception: NoProcessorException: Cannot find a Processor for: ...
=================================================================
If DataSource or Demultiplexer cannot be created we get error message above.

This message can come from:
	- Manager.createProcessorForContent(...)
	- Manager.createProcessorForSource(...)
	
At the start of processing datasource, processor demultiplexer will be created.

- DataSource are selected by PROTOCOL OF INPUT LOCATOR. 
	
	<protocol-prefix>.media.protocol.<protocol>.DataSource
	
	SEE MORE:	 Lookup algorythm of processing elements

- Processor:	selected by content type of source

		<content-prefix>.media.processor.<content type>.Handler

	NOTE: if processor handler nor found with contentName, "unknown" will be applied as contentName and
	
			com.sun.media.processor.unknown.Handler
		
		will be used.
	
- Demultiplexer:	Demultiplexers are plugins that are loaded by PluginManager by CONTENT TYPE OF INPUT DATA SOURCE.
		
	SEE MORE:	How demultiplexers are selected for input data source?
	
		
If DataSource or Demultiplexer cannot be created we get error message above.
Processor for unknown format can be always instantiated.

SEE MORE:
	How DataSources are created?
	How demultiplexers are selected for input data source?


---------------------------------------------------------------------------------------------------------------------------
Exception: CannotRealizeException: Unable to provide all requested tracks
=========================================================================
This error comes from Manager.createRealizedProcessor(ProcessorModel model).

	Model specifies 
		- input (data source or locator) and  
		- output content type and 
		- desired output format(s). 


During processing tracks will be set enabled which format can be set to desired output format.
It comes when JMF is not able to build a plugin graph to provide media with the requested output format.

Building a chain:
- Root input source format of plugin graph comes from demultiplexer output.

	- Demultiplexers are plugins that are loaded by PluginManager by CONTENT TYPE OF INPUT DATA SOURCE.

		- DataSources are selected by PROTOCOL OF INPUT LOCATOR.

- Each other plugins will be joined to each other by supported ouput and input formats.
	
- The end of plugin chain is a multiplexer. MUXs have been selected by OUTPUT FORMAT OF PROCESSOR.

SEE MORE:
	Lookup algorythm of processing elements
	
	
---------------------------------------------------------------------------------------------------------------------------
Exception: CannotRealizeException (no message)
==============================================
If DataSource, Processor and Demultiplexer has been created succesfully and YOU DON'T HAVE CUSTOM PLUGIN CHAIN

Call flow is the following:

							-> super.buildGraph()	== SimpleGraphBuilder.buildGraph()
								
								-> setDefaultTargets(tc.getOriginalFormat()))	: to get default target
									if processor output content type is null 
										-> setDefaultTargetRenderer(in)	: to get default render for track format
											-> setDefaultTargetRenderer.setDefaultTargetRenderer(Format in)
											
									if processor output content type is NOT null 	
										-> setDefaultTargetMux()			: to get default multiplexer

If you have DataSource and Demultiplexer 
	- but Multiplexer cannot found (as default target) (in case when processor output format is NOT null),
	- but Renderer not found (as default target) (in case when processor output format is null),
you will get this message .

	
SEE MORE: Processing in details 


---------------------------------------------------------------------------------------------------------------------------
Exception: NoProcessorException: Processor doesn't support output
=================================================================
Supported output content type is which can be multiplexed. To get supported output content types JMF enumerates all 
multiplexers and gets union of supported output formats.

You gets If you call Manager.createRealizedProcessor(ProcessorModel model) but there is no multiplexer plugin at all.

---------------------------------------------------------------------------------------------------------------------------
Log message: The input format is not compatible with the given codec plugin
===========================================================================
For example:

	## Input: g729, 8000.0 Hz, 8-bit, Mono, Signed, 100.0 frame rate, FrameSize=8 bits
	## Custom options specified.
	## A custom codec is specified: com.ibm.media.codec.audio.PCMToPCM@269be2b5 

That means JMF unable to build codec chain between input format (output of previous node) and
specified custom codec.

If codec is the first codec in the chain input is the track format from demultiplexed input data source.

---------------------------------------------------------------------------------------------------------------------------
How media duration will be calculated?
======================================
You can get calculated duration of media from:	 Duration.getDuration();

NOTE:		=> means implements/extends (is a)

In default processing it's implmented by com.sun.media.BasicPlayer:

	Processor:	com.sun.media.processor.unknown.Handler
					=> com.sun.media.MediaProcessor 
						=> com.sun.media.BasicProcessor (=> Processor)
							=> com.sun.media.BasicPlayer (=> Player, ControllerListener, DownloadProgressListener)
								=> com.sun.media.BasicController (=> Controller, Duration)
							
					
BasicPlayer.getDuration()
	-> updateDuration()
		-------------------------------------- loop on list of controllers -------------------------------------------
		Controller.getDuration()
		by default in an RTP session Controller implemented by PlaybackEngine
		-> PlaybackEngine.getDuration()
			-> BasicSourceModule.getDuration()
				-> Demultiplexer.getDuration()


---------------------------------------------------------------------------------------------------------------------------
Log message:  No multiplexer is found for that content type
===========================================================
				
---------------------------------------------------------------------------------------------------------------------------
JMF Studio source in Maven project
==================================
				
	d:\WORK_PRIVATE\work\general\jmf\JMStudio 
				
				
---------------------------------------------------------------------------------------------------------------------------
Format chooser in JMF
=====================
JMStudion contains media chooser panel:


	jmapps.export.PanelMediaTargetFormat
					
---------------------------------------------------------------------------------------------------------------------------
Call stack of media format chooser (Called from JMStudio)
=========================================================
- JMSTUDIO/File/Transmit

	--> dlgTransmit = JMStudio.transmitMedia()
		--> new TransmitWizard()
			--> ExportWizard()
				--> onPageActivate(PanelMediaSource)
					- rendering input media page ('RTP Transmit')
			- RAW_RTP ("raw.rtp") to TransmitWizard.panelTargetFormat.arrAllowContentType
	
	--> dlgTransmit.show()----------------|
		                                  |
		                                  |
 |----------------------------------------|
 |
 |      AFTER WIZARD CONFIGURATION
 |      -------------------------- if action ACTION_FINISH -------------------
 |      --> mediaPlayer = JMFUtils.createMediaPlayer(processorTransmit, ...)
 |      --> open(mediaPlayer)
 |          --> open(mediaPlayer, true)
 |              --> mediaPlayer.realize()
 |      ############################## PLAYING MEDIA ########################################
 V	
 
	
- on 'RTP Transmit' page choose an audio file and click 'Next'
	


	--> ProcessEngine.doConfigure()
		-->  new ProcessEngine.ProcTControl(...)
			--> BasicTrackControl.BasicTrackControl

	--> jmapps.export.ExportWizard
		================= closing media source page ================
		--> onPageDone(panelPage)				// PanelMediaSource
			--> processor = PanelMediaSource.createProcessor()
				--> mediaSource = new MediaLocator(strSourceUrl)						// file:C:\Users\ftoth\Documents\media\nobody-8000Hz-16b-mono.wav
				--> dataSource = Manager.createDataSource(mediaSource)
				--> processor = Manager.createProcessor(dataSource)
			--> configureProcessor()									// it's just about waiting for processor to be configured
			
		================= opening output format chooser page ================
		--> onPageActivate(...)
			------------------- panelPage == jmapps.export.PanelMediaTargetFormat  --------------------
			--> PanelMediaTargetFormat.setProcessor ( processor, strContentType, strTargetType )      // strContentType: audio.x_wav; strTargetType: "Transmit over the network"
				- setting processor of wizard page
				--> arrContentDescriptors = processor.getSupportedContentDescriptors()		// getting supported content descriptors (RAW, RAW/RTP, WAV, AVI, ...)
				--> arrTrackControls = processor.getTrackControls()							// getting track controls (==> ProcTControl)
				- removing all panel content 
				--> PanelMediaTargetFormat.buildPage()
					- BUILDING DROPDOWN: Format
						------------------------ loop on content descriptors ------------------------
						- building a dropdown with content descriptor strings for output format
						- building a map, where key is dropdown item label and value is content descriptor. E.g:
	
							key: RAW/RTP	value: content descriptor (javax.media.protocol.ContentDescriptor)
							
					--> PanelMediaTargetFormat.buildTrackFormatPanel()			// output audio track configuration
						------------------------ loop on output tracks ------------------------
							format = input format from track control 					// LINEAR, 8000.0 Hz, 16-bit, Mono, LittleEndian, Signed, 16000.0 frame rate, FrameSize=16 bits)
							- choosing track tab label									// Audio
							- getting encoding from input format						// LINEAR
							--> supFormats = arrTrackControls[i].getSupportedFormats() 
								- getting supported format from track control
								==> ProcTControl.getSupportedFormats()					// Here ProcTControl.supportedFormats is still null. It will be loaded on-demand from configuration DB.
									- verifyMuxInputs(...)								// first cd:ROW, loaded formats not filtered
							
								>>>>>>> PanelMediaTargetFormat.supFormats still contains all formats
							
							--> new AudioFormatChooser(supFormats, ...)
								- supFormats ==> vectorContSuppFormats
								--> init()
									- building format page input elements
									- collecting encodings into 
										- comboEncoding
										AND
										- vectorEncoding
									--> updateFields(...)
										--> updateFieldsFromEncoding(formatDefault))
											- collecting encodings into 
												- comboSampleRate
												AND
												- vectorRates											
											--> updateFieldsFromRate(formatDefault)
												--> updateFieldsFromBits(formatDefault)
													--> updateFieldsFromChannels(formatDefault)
														--> updateFieldsFromEndian(formatDefault)
															--> updateFieldsFromSigned(formatDefault)
										
				--> PanelMediaTargetFormat.changeContentType ()
					--> setSupportedFormats(supFormats, fmt)
						--> processor.setContentDescriptor(contentDescriptor) 		// RAW/RTP
							==> com.sun.media.MediaProcessor.setContentDescriptor(contentDescriptor)
							---------------------- loop on audio tracks ----------------------
								--> supFormats = trackControl.getSupportedFormats()
									==> ProcTControl.getSupportedFormats()					// Here ProcTControl.supportedFormats is still contains all formats (loaded before from DB)
										--> verifyMuxInputs(...)								// now cd:ROW/RTP -> formats filtered by RTP MUX
											mux: com.sun.media.multiplexer.RTPSyncBufferMux
											--> SimpleGraphBuilder.createPlugIn
											---------------------- filteringloop on original input formats -----------------
												--> RTPSyncBufferMux.setInputFormat(format, trackID)
													--> !RTPSessionMgr.formatSupported ? null : ...				// check if format is supported by MUX
														--> supportedList.getPayload(format)				// looking for format in FormatInfo.formatList which contains default supported formats indexed by payload type
															IF NOT FOUND
															------------------ loop on (static) added list --------------------
arrContentDescriptors: 9
arrTrackControls: 1
supFormats: 266
vectorContSuppFormats: 266
comboEncoding: 11
vectorRates: 7					
					
									
---------------------------------------------------------------------------------------------------------------------------
How to add custom format (and payload type) to RTP session?
===========================================================
Supported formats are checked twice during RTP transmission.

1. Building codec chain 

	--> ProcessorModel m = new ProcessorModel(inputLocator, formats, contentType);
			inputLocator: URL pointing to input media (file), e.g: file:/c:/Users/ftoth/Documents/media/pcm-8000Hz-16b-mono.wav
			formats: desired output format, e.g: ALAW/rtp, 8000.0 Hz, 8-bit, Mono, 8000.0 frame rate, FrameSize=8 bits
			contentType: content type of output media, e.g: raw.rtp
			
	--> Processor processor = Manager.createRealizedProcessor(m);
		--> com.sun.media.ProcTControl.getSupportedFormats()
			--> verifyMuxInputs(...)
				--> if javax.media.Multiplexer.setInputFormat(...)							// collecting suported formats
					==> com.sun.media.multiplexer.RTPSyncBufferMux.formatSupported(Format input, int trackID) 
						--> RTPSessionMgr.formatSupported(input) 
							--> if supportedList.getPayload(format)							// looking for format in built-in formatList (ALAW is missing here)
								formatList contains 14 built-in RTP formats 				
							--> OR loop on static RTPSessionMgr.addedList 					// it's empty by default but you can add entries via RTPSessionMgr.addFormat(...)
							
							
2. Beginning of transmission
	--> org.ftoth.general.util.jmf.MediaProcessor.initAndStart()
		--> presenting() and presentingTarget == RTPManager
			--> startTransmitter(rtpTargetAddress, rtpTargetPort)
				--> RTPSessionMgr.createSendStream(...)
					--> payload = this.formatinfo.getPayload(fmt);
					------------------------ payload == -1 ------------------------
					--> throw new UnsupportedFormatException("Format of Stream not supported in RTP Session Manager", fmt);					<<<< error here if format not known


	

How to add?
-----------
1. Before calling createRealizedProcessor(...) call initCustomFormatsForProcessor() which creates a dummy RTPSessionMgr instance and adds 
	item to static RTPSessionMgr.addedList list.
	
	OTHERWISE YOU WILL GET THIS ERROR:
	
		javax.media.CannotRealizeException: Unable to provide all requested tracks
			at javax.media.Manager.createRealizedProcessor(Manager.java:908)
			at org.ftoth.general.util.jmf.JmfFactory.createRealizedProcessor(JmfFactory.java:35)
			at org.ftoth.general.util.jmf.JmfFactory.createRealizedProcessor(JmfFactory.java:25)	
			...
			
2. Before creating real RTPSessionMgr instances get custom formats from initCustomFormatsForRtp() again and add to 
	RTPSessionMgr instances.
	
	Map<Integer, Format> customFormats = initCustomFormatsForRtp();
	...
	RTPManager mgr = RTPManager.newInstance();
	for (Integer payloadType : customFormats.keySet()) {
		Format fmt = customFormats.get(payloadType);
		mgr.addFormat(fmt, payloadType);
	}

	OTHERWISE YOU WILL GET THIS ERROR:
	
		javax.media.format.UnsupportedFormatException: Format of Stream not supported in RTP Session Manager
			at com.sun.media.rtp.RTPSessionMgr.createSendStream(RTPSessionMgr.java:1104)
			at com.sun.media.rtp.RTPSessionMgr.createSendStream(RTPSessionMgr.java:1262)
			....
	
For detecting of supported format see also:

	Call stack of media format chooser (Called from JMStudio)

			

Source code
-----------				
	
	private Map<Integer, Format> initCustomFormatsForRtp()
	{
		Map<Integer, Format> formats = new HashMap<Integer, Format>();

		// <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< add here custom codecs
		
		// for example: ALAW
		org.ftoth.general.util.onesec.codec.alaw.libjitsi.Packetizer alawPck = new org.ftoth.general.util.onesec.codec.alaw.libjitsi.Packetizer();
		Format alawInFormat = (alawPck.getSupportedInputFormats())[0];
		Format alawRtpFormat = (alawPck.getSupportedOutputFormats(alawInFormat))[0];
		formats.put(8, alawRtpFormat);
		if (log.isDebugEnabled()) {
			log.debug("ALAW Packetizer (" + org.ftoth.general.util.onesec.codec.alaw.libjitsi.Packetizer.class.getName() + ") successfully added");
		}

		return formats;
	}
	
	
	private void initCustomFormatsForProcessor()
	{
		// dummy (to access internal static format list via non-static addFormat() )
		RTPSessionMgr mgr = JMFUtils.createSessionManager("127.0.0.1", 65000, 32, new ReceiveStreamListener()
		{
			public void update(ReceiveStreamEvent receiveStreamEvent)
			{
				// do nothing
			}
		});

		Map<Integer, Format> customFormats = initCustomFormatsForRtp();

		for (Integer payloadType : customFormats.keySet()) {
			Format fmt = customFormats.get(payloadType);
			mgr.addFormat(fmt, payloadType);
		}
	}
	

---------------------------------------------------------------------------------------------------------------------------
Exception: Format of Stream not supported in RTP Session Manager
================================================================
Yuo gets this error if RTP session manager does not know output format of 

SEE ALSO:	How to add custom format (and payload type) to RTP session?

				
				